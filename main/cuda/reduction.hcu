#if !defined(_REDUCTION_HCU_)
#define _REDUCTION_HCU_

#include "fma.hcu"
#include "vectorMin.hcu"

inline __device__ float fminf(float a, float b, float ia, float ib, float& i)
{
  if (a<=b) {i=ia; return a; }
  else {i=ib; return b; }
}

inline __device__ float fminf(float a, float b, int ia, int ib, int& i)
{
  if (a<=b) {i=ia; return a; }
  else {i=ib; return b; }
}

__inline__ __device__ float2 fminf(float2 a, float2 b, float2 ia, float2 ib, float2& i)
{
  return make_float2(fminf(a.x,b.x,ia.x,ib.x,i.x), 
		     fminf(a.y,b.y,ia.y,ib.y,i.y));
}

__inline__ __device__ float4 fminf(float4 a, float4 b, float4 ia, float4 ib, float4& i)
{
  return make_float4(fminf(a.x,b.x,ia.x,ib.x,i.x), 
		     fminf(a.y,b.y,ia.y,ib.y,i.y), 
		     fminf(a.z,b.z,ia.z,ib.z,i.z), 
		     fminf(a.w,b.w,ia.w,ib.w,i.w));
}


inline __device__ double fmind(double a, double b, double ia, double ib, double& i)
{
  if (a<=b) {i=ia; return a; }
  else {i=ib; return b; }
}

inline __device__ double fmind(double a, double b, int ia, int ib, int& i)
{
  if (a<=b) {i=ia; return a; }
  else {i=ib; return b; }
}

__inline__ __device__ double2 fmind(double2 a, double2 b, double2 ia, double2 ib, double2& i)
{
  return make_double2(fmind(a.x,b.x,ia.x,ib.x,i.x), 
		      fmind(a.y,b.y,ia.y,ib.y,i.y));
}

__inline__ __device__ double4 fmind(double4 a, double4 b, double4 ia, double4 ib, double4& i)
{
  return make_double4(fmind(a.x,b.x,ia.x,ib.x,i.x), 
		      fmind(a.y,b.y,ia.y,ib.y,i.y), 
		      fmind(a.z,b.z,ia.z,ib.z,i.z), 
		      fmind(a.w,b.w,ia.w,ib.w,i.w));
}


template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction1(const int r, const int c, float2 * Creg,
					   float2 A[TILESIZEY][T1],
					   float2 B[TILESIZEY][T2],
					   float * __restrict__ C,
					   int * __restrict__ Cindices) {

}

template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction1(const int r, const int c, double2 * Creg,
					   double2 A[TILESIZEY][T1],
					   double2 B[TILESIZEY][T2],
					   double * __restrict__ C,
					   int * __restrict__ Cindices) {
}


template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction1(const int r, const int c, float4 * Creg,
					   float4 A[TILESIZEY][T1],
					   float4 B[TILESIZEY][T2],
					   float * __restrict__ C,
					   int * __restrict__ Cindices) {

  int4 i;
  int4 j;
  float4 s, t;

  vectorMax<float,float4>(Creg[0],s.x,i.x);
  vectorMax<float,float4>(Creg[1],s.y,i.y);
  vectorMax<float,float4>(Creg[2],s.z,i.z);
  vectorMax<float,float4>(Creg[3],s.w,i.w);

  i.x+=c;
  i.y+=c;
  i.z+=c;
  i.w+=c;
  
  for (int n=1; n<TILESIZE; n<<=1) {
    t.x = __shfl_down(s.x, n, TILESIZE);
    j.x = __shfl_down(i.x, n, TILESIZE);

    t.y = __shfl_down(s.y, n, TILESIZE);
    j.y = __shfl_down(i.y, n, TILESIZE);

    t.z = __shfl_down(s.z, n, TILESIZE);
    j.z = __shfl_down(i.z, n, TILESIZE);

    t.w = __shfl_down(s.w, n, TILESIZE);
    j.w = __shfl_down(i.w, n, TILESIZE);

    if ((threadIdx.x%(n*2))==0) {
      if (s.x<t.x) { i.x = j.x; s.x=t.x; }
      if (s.y<t.y) { i.y = j.y; s.y=t.y; }
      if (s.z<t.z) { i.z = j.z; s.z=t.z; }
      if (s.w<t.w) { i.w = j.w; s.w=t.w; }
    }
  }

  t.w = __shfl_up(s.w, 3, TILESIZE);
  j.w = __shfl_up(i.w, 3, TILESIZE);

  t.z = __shfl_up(s.z, 2, TILESIZE);
  j.z = __shfl_up(i.z, 2, TILESIZE);

  t.y = __shfl_up(s.y, 1, TILESIZE);
  j.y = __shfl_up(i.y, 1, TILESIZE);

  t.x = s.x;
  j.x = i.x;

  float * a = reinterpret_cast<float *>(&t);
  int * b = reinterpret_cast<int *>(&j);

  /* write out the results */
  if (threadIdx.x<4) {
    int k = r+threadIdx.x;
    if (k<dev_nRowsA) {
      int index = k*dev_nColsC+blockIdx.x;
      C[index]        = -2.0f*a[threadIdx.x];
      Cindices[index] = b[threadIdx.x];
    }
  }
}

template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction1(const int r, const int c, double4 * Creg,
					   double4 A[TILESIZEY][T1],
					   double4 B[TILESIZEY][T2],
					   double * __restrict__ C,
					   int * __restrict__ Cindices) {
  
}



template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction(const int c, float2 * Creg,
					  float2 L2normB[TILESIZE],
					  float2 A[TILESIZEY][T1],
					  float2 B[TILESIZEY][T2]) {

  int tidx = threadIdx.x;
  int tidy = threadIdx.y;

  int2 i;
  float2 s;
  float2 t = L2normB[tidx];

  Creg[0] = fma<float,float2>(-2.0f,Creg[0],t);
  vectorMin<float,float2>(Creg[0],s.x,i.x);
  
  Creg[1] = fma<float,float2>(-2.0f,Creg[1],t);
  vectorMin<float,float2>(Creg[1],s.y,i.y);

  i.x+=c;
  i.y+=c;

#if __CUDA_ARCH__ < 300
  A[tidy][tidx] = s;
  B[tidy][tidx] = make_float2(i.x,i.y);  
    
  /* perform the partial reduction over each row in the  buffers */
  if (tidx%2==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+1],
			  B[tidy][tidx],B[tidy][tidx+1],s);
    B[tidy][tidx] = s;
  }
  if (tidx%4==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+2],
			  B[tidy][tidx],B[tidy][tidx+2],s);
    B[tidy][tidx] = s;
  }
  if (tidx%8==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+4],
			  B[tidy][tidx],B[tidy][tidx+4],s);
    B[tidy][tidx] = s;
  }
  if (tidx==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+8],
			  B[tidy][tidx],B[tidy][tidx+8],s);
    B[tidy][tidx] = s;
  }
#else
  int2 j;
  for (int k=1; k<TILESIZE; k<<=1) {

    t.x = __shfl_down(s.x, k, TILESIZE);
    j.x = __shfl_down(i.x, k, TILESIZE);

    t.y = __shfl_down(s.y, k, TILESIZE);
    j.y = __shfl_down(i.y, k, TILESIZE);

    if ((tidx%(k*2))==0) {
      if (s.x>t.x) { i.x = j.x; s.x=t.x; }
      if (s.y>t.y) { i.y = j.y; s.y=t.y; }
    }
  }

  if (tidx==0) {
    A[tidy][0] = s;
    B[tidy][0] = make_float2(i.x,i.y);  
  }
#endif
}

template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction(const int c, double2 * Creg,
					  double2 L2normB[TILESIZE],
					  double2 A[TILESIZEY][T1],
					  double2 B[TILESIZEY][T2]) {

  int tidx = threadIdx.x;
  int tidy = threadIdx.y;

  int2 i;
  double2 s;
  double2 t = L2normB[tidx];

  Creg[0] = fma<double,double2>(-2.0,Creg[0],t);
  vectorMin<double,double2>(Creg[0],s.x,i.x);
  
  Creg[1] = fma<double,double2>(-2.0,Creg[1],t);
  vectorMin<double,double2>(Creg[1],s.y,i.y);
    
  A[tidy][tidx] = s;
  B[tidy][tidx] = make_double2(i.x+c,i.y+c);
  
  __syncthreads();
    
  /* perform the partial reduction over each row in the  buffers */
  if (tidx%2==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+1],
			  B[tidy][tidx],B[tidy][tidx+1],s);
    B[tidy][tidx] = s;
  }
  if (tidx%4==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+2],
			  B[tidy][tidx],B[tidy][tidx+2],s);
    B[tidy][tidx] = s;
  }
  if (tidx%8==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+4],
			  B[tidy][tidx],B[tidy][tidx+4],s);
    B[tidy][tidx] = s;
  }
  if (tidx==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+8],
			  B[tidy][tidx],B[tidy][tidx+8],s);
    B[tidy][tidx] = s;
  }
  __syncthreads();
}

template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction(const int c, float4 * Creg,
					  float4 L2normB[TILESIZE],
					  float4 A[TILESIZEY][T1],
					  float4 B[TILESIZEY][T2]) {

  int tidx = threadIdx.x;
  int tidy = threadIdx.y;

  int4 i;
  float4 s;
  float4 t = L2normB[tidx];

  Creg[0] = fma<float,float4>(-2.0f,Creg[0],t);
  vectorMin<float,float4>(Creg[0],s.x,i.x);
  
  Creg[1] = fma<float,float4>(-2.0f,Creg[1],t);
  vectorMin<float,float4>(Creg[1],s.y,i.y);
  
  Creg[2] = fma<float,float4>(-2.0f,Creg[2],t);
  vectorMin<float,float4>(Creg[2],s.z,i.z);
  
  Creg[3] = fma<float,float4>(-2.0f,Creg[3],t);
  vectorMin<float,float4>(Creg[3],s.w,i.w);

  i.x+=c;
  i.y+=c;
  i.z+=c;
  i.w+=c;

#if __CUDA_ARCH__ < 300
  A[tidy][tidx] = s;
  B[tidy][tidx] = make_float4(i.x,i.y,i.z,i.w);  
    
  /* perform the partial reduction over each row in the  buffers */
  if (tidx%2==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+1],
			  B[tidy][tidx],B[tidy][tidx+1],s);
    B[tidy][tidx] = s;
  }
  if (tidx%4==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+2],
			  B[tidy][tidx],B[tidy][tidx+2],s);
    B[tidy][tidx] = s;
  }
  if (tidx%8==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+4],
			  B[tidy][tidx],B[tidy][tidx+4],s);
    B[tidy][tidx] = s;
  }
  if (tidx==0) {
    A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+8],
			  B[tidy][tidx],B[tidy][tidx+8],s);
    B[tidy][tidx] = s;
  }
#else 
  int4 j;
  for (int k=1; k<TILESIZE; k<<=1) {

    t.x = __shfl_down(s.x, k, TILESIZE);
    j.x = __shfl_down(i.x, k, TILESIZE);

    t.y = __shfl_down(s.y, k, TILESIZE);
    j.y = __shfl_down(i.y, k, TILESIZE);

    t.z = __shfl_down(s.z, k, TILESIZE);
    j.z = __shfl_down(i.z, k, TILESIZE);

    t.w = __shfl_down(s.w, k, TILESIZE);
    j.w = __shfl_down(i.w, k, TILESIZE);

    if ((tidx%(k*2))==0) {
      if (s.x>t.x) { i.x = j.x; s.x=t.x; }
      if (s.y>t.y) { i.y = j.y; s.y=t.y; }
      if (s.z>t.z) { i.z = j.z; s.z=t.z; }
      if (s.w>t.w) { i.w = j.w; s.w=t.w; }
    }
  }

  if (tidx==0) {
    A[tidy][0] = s;
    B[tidy][0] = make_float4(i.x,i.y,i.z,i.w);  
  }
#endif
}

template<const int T1, const int T2>
__device__ __inline__ void _dev_reduction(const int c, double4 * Creg,
					  double4 L2normB[TILESIZE],
					  double4 A[TILESIZEY][T1],
					  double4 B[TILESIZEY][T2]) {

  int tidx = threadIdx.x;
  int tidy = threadIdx.y;

  int4 i;
  double4 s;
  double4 t = L2normB[tidx];

  Creg[0] = fma<double,double4>(-2.0,Creg[0],t);
  vectorMin<double,double4>(Creg[0],s.x,i.x);
  
  Creg[1] = fma<double,double4>(-2.0,Creg[1],t);
  vectorMin<double,double4>(Creg[1],s.y,i.y);
  
  Creg[2] = fma<double,double4>(-2.0,Creg[2],t);
  vectorMin<double,double4>(Creg[2],s.z,i.z);
  
  Creg[3] = fma<double,double4>(-2.0,Creg[3],t);
  vectorMin<double,double4>(Creg[3],s.w,i.w);
  
  A[tidy][tidx] = s;
  B[tidy][tidx] = make_double4(i.x+c,i.y+c,i.z+c,i.w+c);  
  __syncthreads();
    
  /* perform the partial reduction over each row in the  buffers */
  if (tidx%2==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+1],
			  B[tidy][tidx],B[tidy][tidx+1],s);
    B[tidy][tidx] = s;
  }
  if (tidx%4==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+2],
			  B[tidy][tidx],B[tidy][tidx+2],s);
    B[tidy][tidx] = s;
  }
  if (tidx%8==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+4],
			  B[tidy][tidx],B[tidy][tidx+4],s);
    B[tidy][tidx] = s;
  }
  if (tidx==0) {
    A[tidy][tidx] = fmind(A[tidy][tidx],A[tidy][tidx+8],
			  B[tidy][tidx],B[tidy][tidx+8],s);
    B[tidy][tidx] = s;
  }
  __syncthreads();
}

// template<class TYPE, const int T1, const int T2, const int N_UNROLL>
// __device__ __inline__ void _dev_reduction(const int c, TYPE Creg[N_UNROLL*N_UNROLL],
// 					  TYPE L2normB[N_UNROLL*TILESIZE],
// 					  TYPE A[N_UNROLL*TILESIZEY][T1],
// 					  TYPE B[N_UNROLL*TILESIZEY][T2]) {

//   int tidx = threadIdx.x;
//   int tidy = threadIdx.y;

//   int4 i;
//   float4 s;
//   float4 t = L2normB[tidx];

//   Creg[0] = fma<float,float4>(-2.0f,Creg[0],t);
//   vectorMin<float,float4>(Creg[0],s.x,i.x);
  
//   Creg[1] = fma<float,float4>(-2.0f,Creg[1],t);
//   vectorMin<float,float4>(Creg[1],s.y,i.y);
  
//   Creg[2] = fma<float,float4>(-2.0f,Creg[2],t);
//   vectorMin<float,float4>(Creg[2],s.z,i.z);
  
//   Creg[3] = fma<float,float4>(-2.0f,Creg[3],t);
//   vectorMin<float,float4>(Creg[3],s.w,i.w);

//   A[tidy][tidx] = s;
//   B[tidy][tidx] = make_float4(i.x+c,i.y+c,i.z+c,i.w+c);  
//   __syncthreads();
    
//   /* perform the partial reduction over each row in the  buffers */
//   if (tidx%2==0) {
//     A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+1],
// 			  B[tidy][tidx],B[tidy][tidx+1],s);
//     B[tidy][tidx] = s;
//   }
//   if (tidx%4==0) {
//     A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+2],
// 			  B[tidy][tidx],B[tidy][tidx+2],s);
//     B[tidy][tidx] = s;
//   }
//   if (tidx%8==0) {
//     A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+4],
// 			  B[tidy][tidx],B[tidy][tidx+4],s);
//     B[tidy][tidx] = s;
//   }
//   if (tidx==0) {
//     A[tidy][tidx] = fminf(A[tidy][tidx],A[tidy][tidx+8],
// 			  B[tidy][tidx],B[tidy][tidx+8],s);
//     B[tidy][tidx] = s;
//   }
//   __syncthreads();
// }

#endif /* !defined(_REDUCTION_HCU_) */
